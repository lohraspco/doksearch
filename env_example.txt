# OpenAI Configuration
# Get your API key from https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Optional: Override default model
# OPENAI_MODEL=gpt-4

# Local LLM Configuration
# Set to true to use local models instead of OpenAI (default: true)
USE_LOCAL_LLM=true

# Local LLM Provider (ollama, transformers)
LOCAL_LLM_PROVIDER=ollama

# Local LLM Model (for Ollama: gemma2:3b, llama3.2:3b, etc.)
LOCAL_LLM_MODEL=gemma2:3b

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434

# Embedding Model Configuration
# Primary embedding model used throughout the app
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Local Embeddings Configuration
# Set to true to use local embedding models
USE_LOCAL_EMBEDDINGS=false

# Local Embedding Model (used when USE_LOCAL_EMBEDDINGS=true)
LOCAL_EMBEDDING_MODEL=nomic-embed-text

# Model Loading Settings
LOAD_IN_8BIT=false
LOAD_IN_4BIT=false
DEVICE_MAP=auto

# Optional: Override default settings
# CHUNK_SIZE=1000
# CHUNK_OVERLAP=200
# TOP_K_RESULTS=5
# SIMILARITY_THRESHOLD=0.7 